{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit wallstreetbets back-test\n",
    "\n",
    "We use historical wsb subreddit data to back-test a trading strategy. The approach is to use a sliding window approach, for each window, we use OpenAI to perform a summary and suggest trends.\n",
    "\n",
    "Once we have the trends, we can evaluate the performance of the tickers from the time they first appeared as an investment suggestion. We can test various holding periods, e.g.: 1 day, 1 week, 1 month, etc.\n",
    "\n",
    "Before you begin, you need to download the wsb data. You can do so by running the following command:\n",
    "\n",
    "```bash\n",
    "# install the Google Cloud SDK\n",
    "brew install google-cloud-sdk\n",
    "\n",
    "# authenticate using any google account\n",
    "gcloud auth login\n",
    "\n",
    "#execute the script\n",
    "./scripts/extract-wsb-data.sh\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utility' from '/Users/tiang/dev/genai/fintechx/notebooks/utility/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/wsb/export2017.json', '../data/wsb/export2016.json', '../data/wsb/export2015.json', '../data/wsb/export2019.json', '../data/wsb/export2018.json']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'utility' from '/Users/tiang/dev/genai/fintechx/notebooks/utility/__init__.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload module\n",
    "\n",
    "from importlib import reload\n",
    "import utility\n",
    "\n",
    "reload(utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.embeddings import (\n",
    "    OpenAIEmbeddings,\n",
    "    HuggingFaceEmbeddings,\n",
    "    LlamaCppEmbeddings,\n",
    ")\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "import qdrant_client\n",
    "\n",
    "from utility import try_index, try_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_-</td>\n",
       "      <td>I am sick of seeing so many wars fought for th...</td>\n",
       "      <td>1509925069</td>\n",
       "      <td>1.512165e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_o</td>\n",
       "      <td>RemindMe! 3 months</td>\n",
       "      <td>1485566519</td>\n",
       "      <td>1.486498e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1HD</td>\n",
       "      <td>So... Star Wars?</td>\n",
       "      <td>1499010109</td>\n",
       "      <td>1.499844e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1Ra</td>\n",
       "      <td>The upsy-downsy heartbeat. you can expect it t...</td>\n",
       "      <td>1483561320</td>\n",
       "      <td>1.485778e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1jb</td>\n",
       "      <td>Atta boy</td>\n",
       "      <td>1502397647</td>\n",
       "      <td>1.503944e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886813</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1516927432</td>\n",
       "      <td>1.518287e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886814</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1515296914</td>\n",
       "      <td>1.517644e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886815</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1515061012</td>\n",
       "      <td>1.517552e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886816</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1516761637</td>\n",
       "      <td>1.518222e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886817</th>\n",
       "      <td>Delightful_Dantonio</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1532302837</td>\n",
       "      <td>1.536395e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6795190 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      author  \\\n",
       "0                        0_-   \n",
       "1                        0_o   \n",
       "2                        1HD   \n",
       "3                        1Ra   \n",
       "4                        1jb   \n",
       "...                      ...   \n",
       "1886813            [deleted]   \n",
       "1886814            [deleted]   \n",
       "1886815            [deleted]   \n",
       "1886816            [deleted]   \n",
       "1886817  Delightful_Dantonio   \n",
       "\n",
       "                                                      body  created_utc  \\\n",
       "0        I am sick of seeing so many wars fought for th...   1509925069   \n",
       "1                                       RemindMe! 3 months   1485566519   \n",
       "2                                         So... Star Wars?   1499010109   \n",
       "3        The upsy-downsy heartbeat. you can expect it t...   1483561320   \n",
       "4                                                Atta boy    1502397647   \n",
       "...                                                    ...          ...   \n",
       "1886813                                          [removed]   1516927432   \n",
       "1886814                                          [removed]   1515296914   \n",
       "1886815                                          [removed]   1515061012   \n",
       "1886816                                          [removed]   1516761637   \n",
       "1886817                                          [removed]   1532302837   \n",
       "\n",
       "         retrieved_on       subreddit  \n",
       "0        1.512165e+09  wallstreetbets  \n",
       "1        1.486498e+09  wallstreetbets  \n",
       "2        1.499844e+09  wallstreetbets  \n",
       "3        1.485778e+09  wallstreetbets  \n",
       "4        1.503944e+09  wallstreetbets  \n",
       "...               ...             ...  \n",
       "1886813  1.518287e+09  wallstreetbets  \n",
       "1886814  1.517644e+09  wallstreetbets  \n",
       "1886815  1.517552e+09  wallstreetbets  \n",
       "1886816  1.518222e+09  wallstreetbets  \n",
       "1886817  1.536395e+09  wallstreetbets  \n",
       "\n",
       "[6795190 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "wsb_files = glob.glob(\"../data/wsb/*.json\")\n",
    "# print(wsb_files)\n",
    "\n",
    "# file='../data/wsb/export2017.json'\n",
    "# wsb_df = pd.read_json(file)\n",
    "\n",
    "wsb_df = pd.concat([pd.read_json(f) for f in wsb_files])\n",
    "wsb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_utc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:12:14</th>\n",
       "      <td>aspiringanalyst</td>\n",
       "      <td>Complex - yes  - but from patient perspective ...</td>\n",
       "      <td>2015-01-01 00:12:14</td>\n",
       "      <td>2015-02-28 11:48:53</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:09:12</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2015-01-01 03:09:12</td>\n",
       "      <td>2015-02-28 11:15:24</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 06:39:01</th>\n",
       "      <td>phqu88</td>\n",
       "      <td>nflx, earnings coming up</td>\n",
       "      <td>2015-01-01 06:39:01</td>\n",
       "      <td>2015-02-28 10:43:30</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 12:41:22</th>\n",
       "      <td>MagnusMcLongcock</td>\n",
       "      <td>Plenty of free apps provide real-time data.</td>\n",
       "      <td>2015-01-01 12:41:22</td>\n",
       "      <td>2015-02-28 10:08:49</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 17:21:21</th>\n",
       "      <td>proptrader123</td>\n",
       "      <td>not really, lots of fundemental differences be...</td>\n",
       "      <td>2015-01-01 17:21:21</td>\n",
       "      <td>2015-02-28 09:31:48</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:58:51</th>\n",
       "      <td>omgoptions</td>\n",
       "      <td>Wow thank you for the positive feedback. Its r...</td>\n",
       "      <td>2019-12-31 23:58:51</td>\n",
       "      <td>2020-04-09 16:37:17</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:58:52</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>And that’s enough internet for today</td>\n",
       "      <td>2019-12-31 23:58:52</td>\n",
       "      <td>2020-04-09 16:37:17</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:58:56</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>33ish? Thx Obama.</td>\n",
       "      <td>2019-12-31 23:58:56</td>\n",
       "      <td>2020-04-09 16:37:21</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:59:12</th>\n",
       "      <td>phoq5</td>\n",
       "      <td>zaddi?</td>\n",
       "      <td>2019-12-31 23:59:12</td>\n",
       "      <td>2020-04-09 16:37:31</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:59:23</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Lol.</td>\n",
       "      <td>2019-12-31 23:59:23</td>\n",
       "      <td>2020-04-09 16:37:39</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6795190 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               author  \\\n",
       "created_utc                             \n",
       "2015-01-01 00:12:14   aspiringanalyst   \n",
       "2015-01-01 03:09:12         [deleted]   \n",
       "2015-01-01 06:39:01            phqu88   \n",
       "2015-01-01 12:41:22  MagnusMcLongcock   \n",
       "2015-01-01 17:21:21     proptrader123   \n",
       "...                               ...   \n",
       "2019-12-31 23:58:51        omgoptions   \n",
       "2019-12-31 23:58:52         [deleted]   \n",
       "2019-12-31 23:58:56         [deleted]   \n",
       "2019-12-31 23:59:12             phoq5   \n",
       "2019-12-31 23:59:23         [deleted]   \n",
       "\n",
       "                                                                  body  \\\n",
       "created_utc                                                              \n",
       "2015-01-01 00:12:14  Complex - yes  - but from patient perspective ...   \n",
       "2015-01-01 03:09:12                                          [deleted]   \n",
       "2015-01-01 06:39:01                           nflx, earnings coming up   \n",
       "2015-01-01 12:41:22        Plenty of free apps provide real-time data.   \n",
       "2015-01-01 17:21:21  not really, lots of fundemental differences be...   \n",
       "...                                                                ...   \n",
       "2019-12-31 23:58:51  Wow thank you for the positive feedback. Its r...   \n",
       "2019-12-31 23:58:52               And that’s enough internet for today   \n",
       "2019-12-31 23:58:56                                  33ish? Thx Obama.   \n",
       "2019-12-31 23:59:12                                             zaddi?   \n",
       "2019-12-31 23:59:23                                               Lol.   \n",
       "\n",
       "                             created_utc         retrieved_on       subreddit  \n",
       "created_utc                                                                    \n",
       "2015-01-01 00:12:14  2015-01-01 00:12:14  2015-02-28 11:48:53  wallstreetbets  \n",
       "2015-01-01 03:09:12  2015-01-01 03:09:12  2015-02-28 11:15:24  wallstreetbets  \n",
       "2015-01-01 06:39:01  2015-01-01 06:39:01  2015-02-28 10:43:30  wallstreetbets  \n",
       "2015-01-01 12:41:22  2015-01-01 12:41:22  2015-02-28 10:08:49  wallstreetbets  \n",
       "2015-01-01 17:21:21  2015-01-01 17:21:21  2015-02-28 09:31:48  wallstreetbets  \n",
       "...                                  ...                  ...             ...  \n",
       "2019-12-31 23:58:51  2019-12-31 23:58:51  2020-04-09 16:37:17  wallstreetbets  \n",
       "2019-12-31 23:58:52  2019-12-31 23:58:52  2020-04-09 16:37:17  wallstreetbets  \n",
       "2019-12-31 23:58:56  2019-12-31 23:58:56  2020-04-09 16:37:21  wallstreetbets  \n",
       "2019-12-31 23:59:12  2019-12-31 23:59:12  2020-04-09 16:37:31  wallstreetbets  \n",
       "2019-12-31 23:59:23  2019-12-31 23:59:23  2020-04-09 16:37:39  wallstreetbets  \n",
       "\n",
       "[6795190 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert created_utc to datetime\n",
    "wsb_df[\"created_utc\"] = pd.to_datetime(wsb_df[\"created_utc\"], unit=\"s\")\n",
    "# convert retrieved_on to datetime\n",
    "# sort rows by created_utc\n",
    "wsb_df = wsb_df.sort_values(by=\"created_utc\")\n",
    "# create a new index based on created_utc and also keep the old column\n",
    "wsb_df = wsb_df.set_index(\"created_utc\", drop=False)\n",
    "# convert timestamps to datetimes formatted as strings\n",
    "wsb_df[\"retrieved_on\"] = pd.to_datetime(wsb_df[\"retrieved_on\"], unit=\"s\").astype(str)\n",
    "wsb_df[\"created_utc\"] = wsb_df[\"created_utc\"].astype(str)\n",
    "wsb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_utc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:12:14</th>\n",
       "      <td>aspiringanalyst</td>\n",
       "      <td>Complex - yes  - but from patient perspective ...</td>\n",
       "      <td>2015-01-01 00:12:14</td>\n",
       "      <td>2015-02-28 11:48:53</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 06:39:01</th>\n",
       "      <td>phqu88</td>\n",
       "      <td>nflx, earnings coming up</td>\n",
       "      <td>2015-01-01 06:39:01</td>\n",
       "      <td>2015-02-28 10:43:30</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 12:41:22</th>\n",
       "      <td>MagnusMcLongcock</td>\n",
       "      <td>Plenty of free apps provide real-time data.</td>\n",
       "      <td>2015-01-01 12:41:22</td>\n",
       "      <td>2015-02-28 10:08:49</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 17:21:21</th>\n",
       "      <td>proptrader123</td>\n",
       "      <td>not really, lots of fundemental differences be...</td>\n",
       "      <td>2015-01-01 17:21:21</td>\n",
       "      <td>2015-02-28 09:31:48</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 18:55:28</th>\n",
       "      <td>hiphoprising</td>\n",
       "      <td>Yeah I think it'd be better to wait for oil to...</td>\n",
       "      <td>2015-01-01 18:55:28</td>\n",
       "      <td>2015-02-28 09:10:38</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:58:51</th>\n",
       "      <td>omgoptions</td>\n",
       "      <td>Wow thank you for the positive feedback. Its r...</td>\n",
       "      <td>2019-12-31 23:58:51</td>\n",
       "      <td>2020-04-09 16:37:17</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:58:52</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>And that’s enough internet for today</td>\n",
       "      <td>2019-12-31 23:58:52</td>\n",
       "      <td>2020-04-09 16:37:17</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:58:56</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>33ish? Thx Obama.</td>\n",
       "      <td>2019-12-31 23:58:56</td>\n",
       "      <td>2020-04-09 16:37:21</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:59:12</th>\n",
       "      <td>phoq5</td>\n",
       "      <td>zaddi?</td>\n",
       "      <td>2019-12-31 23:59:12</td>\n",
       "      <td>2020-04-09 16:37:31</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:59:23</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Lol.</td>\n",
       "      <td>2019-12-31 23:59:23</td>\n",
       "      <td>2020-04-09 16:37:39</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6198498 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               author  \\\n",
       "created_utc                             \n",
       "2015-01-01 00:12:14   aspiringanalyst   \n",
       "2015-01-01 06:39:01            phqu88   \n",
       "2015-01-01 12:41:22  MagnusMcLongcock   \n",
       "2015-01-01 17:21:21     proptrader123   \n",
       "2015-01-01 18:55:28      hiphoprising   \n",
       "...                               ...   \n",
       "2019-12-31 23:58:51        omgoptions   \n",
       "2019-12-31 23:58:52         [deleted]   \n",
       "2019-12-31 23:58:56         [deleted]   \n",
       "2019-12-31 23:59:12             phoq5   \n",
       "2019-12-31 23:59:23         [deleted]   \n",
       "\n",
       "                                                                  body  \\\n",
       "created_utc                                                              \n",
       "2015-01-01 00:12:14  Complex - yes  - but from patient perspective ...   \n",
       "2015-01-01 06:39:01                           nflx, earnings coming up   \n",
       "2015-01-01 12:41:22        Plenty of free apps provide real-time data.   \n",
       "2015-01-01 17:21:21  not really, lots of fundemental differences be...   \n",
       "2015-01-01 18:55:28  Yeah I think it'd be better to wait for oil to...   \n",
       "...                                                                ...   \n",
       "2019-12-31 23:58:51  Wow thank you for the positive feedback. Its r...   \n",
       "2019-12-31 23:58:52               And that’s enough internet for today   \n",
       "2019-12-31 23:58:56                                  33ish? Thx Obama.   \n",
       "2019-12-31 23:59:12                                             zaddi?   \n",
       "2019-12-31 23:59:23                                               Lol.   \n",
       "\n",
       "                             created_utc         retrieved_on       subreddit  \n",
       "created_utc                                                                    \n",
       "2015-01-01 00:12:14  2015-01-01 00:12:14  2015-02-28 11:48:53  wallstreetbets  \n",
       "2015-01-01 06:39:01  2015-01-01 06:39:01  2015-02-28 10:43:30  wallstreetbets  \n",
       "2015-01-01 12:41:22  2015-01-01 12:41:22  2015-02-28 10:08:49  wallstreetbets  \n",
       "2015-01-01 17:21:21  2015-01-01 17:21:21  2015-02-28 09:31:48  wallstreetbets  \n",
       "2015-01-01 18:55:28  2015-01-01 18:55:28  2015-02-28 09:10:38  wallstreetbets  \n",
       "...                                  ...                  ...             ...  \n",
       "2019-12-31 23:58:51  2019-12-31 23:58:51  2020-04-09 16:37:17  wallstreetbets  \n",
       "2019-12-31 23:58:52  2019-12-31 23:58:52  2020-04-09 16:37:17  wallstreetbets  \n",
       "2019-12-31 23:58:56  2019-12-31 23:58:56  2020-04-09 16:37:21  wallstreetbets  \n",
       "2019-12-31 23:59:12  2019-12-31 23:59:12  2020-04-09 16:37:31  wallstreetbets  \n",
       "2019-12-31 23:59:23  2019-12-31 23:59:23  2020-04-09 16:37:39  wallstreetbets  \n",
       "\n",
       "[6198498 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop any rows that have body == \"[removed]\" or \"[deleted]\" or are empty\n",
    "wsb_df = wsb_df[~wsb_df[\"body\"].isin([\"[removed]\", \"[deleted]\", \"\"])]\n",
    "wsb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = ''\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = ''\n",
    "os.environ['OPENAI_API_BASE'] =  'https://fintechx-oai-eus.openai.azure.com/'\n",
    "os.environ['OPENAI_API_TYPE'] = 'azure'\n",
    "os.environ['OPENAI_API_VERSION'] = '2023-05-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! model is not default parameter.\n",
      "                    model was transfered to model_kwargs.\n",
      "                    Please confirm that model is what you intended.\n",
      "WARNING! openai_api_version is not default parameter.\n",
      "                    openai_api_version was transfered to model_kwargs.\n",
      "                    Please confirm that openai_api_version is what you intended.\n"
     ]
    }
   ],
   "source": [
    "# get env var\n",
    "openai_api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    temperature=0.0,\n",
    "    deployment_name=\"davinci\",\n",
    "    model=\"text-davinci-003\",\n",
    "    openai_api_base=\"https://fintechx-oai-eus.openai.azure.com/\",\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    openai_api_key=openai_api_key,\n",
    "    best_of=3,\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    deployment=\"embeddings\",\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base=\"https://fintechx-oai-eus.openai.azure.com/\",\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    openai_api_key=openai_api_key,\n",
    "    embedding_ctx_length=8191,\n",
    "    # for now the chunk_size has to be 1, due to azure openai limitations, Note:\n",
    "    # We currently do not support batching of embeddings into a single API call.\n",
    "    # If you receive the error InvalidRequestError: Too many inputs. The max\n",
    "    # number of inputs is 1. We hope to increase the number of inputs per request\n",
    "    #  soon., this typically occurs when an array of embeddings is attempted to\n",
    "    # be passed as a batch rather than a single string. The string can be up to\n",
    "    # 8191 tokens in length when using the text-embedding-ada-002 (Version 2) model.\n",
    "    # more: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#embeddings\n",
    "    # chunk_size=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Override the embeddings\n",
    "\n",
    "Because Azure OpenAI has very low rate limits, we can use the embeddings from the OpenAI API to speed up the process. To do so, we can override the embeddings with the cell below.\n",
    "\n",
    "Just append your `OPENAI_API_KEY` to the constructor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = OpenAIEmbeddings(openai_api_key=\"sk-***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m966.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from sentence_transformers) (4.30.2)\n",
      "Requirement already satisfied: tqdm in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from sentence_transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from sentence_transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from sentence_transformers) (0.15.1)\n",
      "Requirement already satisfied: filelock in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\n",
      "Requirement already satisfied: click in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from torchvision->sentence_transformers) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/tiang/dev/genai/.venv/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Building wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=0bf5acb6f0de0afeeb420ea71fc07829cb4ba241fb98df8dfa5988885a576c27\n",
      "  Stored in directory: /Users/tiang/Library/Caches/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: sentence_transformers\n",
      "Successfully installed sentence_transformers-2.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiang/dev/genai/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)a8e1d/.gitattributes: 1.18kB [00:00, 1.58MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 183kB/s]\n",
      "Downloading (…)b20bca8e1d/README.md: 10.6kB [00:00, 10.3MB/s]\n",
      "Downloading (…)0bca8e1d/config.json: 100%|██████████| 571/571 [00:00<00:00, 501kB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 473kB/s]\n",
      "Downloading (…)e1d/data_config.json: 39.3kB [00:00, 48.2MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [01:04<00:00, 6.76MB/s] \n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 92.8kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 1.18MB/s]\n",
      "Downloading (…)a8e1d/tokenizer.json: 466kB [00:00, 1.11MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 363/363 [00:00<00:00, 837kB/s]\n",
      "Downloading (…)8e1d/train_script.py: 13.1kB [00:00, 26.6MB/s]\n",
      "Downloading (…)b20bca8e1d/vocab.txt: 232kB [00:00, 578kB/s] \n",
      "Downloading (…)bca8e1d/modules.json: 100%|██████████| 349/349 [00:00<00:00, 1.01MB/s]\n"
     ]
    }
   ],
   "source": [
    "# in memory embeddings - heavy on cpu\n",
    "! pip install sentence_transformers\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Create the index and persist in Qdrant vectorstore\n",
    "\n",
    "Here, be sure to run `docker compose up -d` in the root of the repo to start the Qdrant server.\n",
    "\n",
    "The cell below is optional, because it is time consuming, we persist the indexes in the Qdrant running in docker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: {'start_date': '2015-01-01', 'end_date': '2015-01-04', 'collection_name': 'wsb_2015-01-01_2015-01-04', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-01-12', 'end_date': '2015-01-18', 'collection_name': 'wsb_2015-01-12_2015-01-18', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-02-02', 'end_date': '2015-02-08', 'collection_name': 'wsb_2015-02-02_2015-02-08', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-01-19', 'end_date': '2015-01-25', 'collection_name': 'wsb_2015-01-19_2015-01-25', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-02-09', 'end_date': '2015-02-15', 'collection_name': 'wsb_2015-02-09_2015-02-15', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-02-16', 'end_date': '2015-02-22', 'collection_name': 'wsb_2015-02-16_2015-02-22', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-01-05', 'end_date': '2015-01-11', 'collection_name': 'wsb_2015-01-05_2015-01-11', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-01-26', 'end_date': '2015-02-01', 'collection_name': 'wsb_2015-01-26_2015-02-01', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-03-30', 'end_date': '2015-04-05', 'collection_name': 'wsb_2015-03-30_2015-04-05', 'error': \"Unexpected Response: 408 (Request Timeout)\\nRaw response content:\\nb''\"}\n",
      "finished: {'start_date': '2015-02-23', 'end_date': '2015-03-01', 'collection_name': 'wsb_2015-02-23_2015-03-01', 'error': \"Unexpected Response: 408 (Request Timeout)\\nRaw response content:\\nb''\"}\n",
      "finished: {'start_date': '2015-04-13', 'end_date': '2015-04-19', 'collection_name': 'wsb_2015-04-13_2015-04-19', 'error': \"Unexpected Response: 408 (Request Timeout)\\nRaw response content:\\nb''\"}\n",
      "finished: {'start_date': '2015-03-16', 'end_date': '2015-03-22', 'collection_name': 'wsb_2015-03-16_2015-03-22', 'error': \"Unexpected Response: 408 (Request Timeout)\\nRaw response content:\\nb''\"}\n",
      "finished: {'start_date': '2015-03-09', 'end_date': '2015-03-15', 'collection_name': 'wsb_2015-03-09_2015-03-15', 'error': \"Unexpected Response: 408 (Request Timeout)\\nRaw response content:\\nb''\"}\n",
      "finished: {'start_date': '2015-04-06', 'end_date': '2015-04-12', 'collection_name': 'wsb_2015-04-06_2015-04-12', 'error': \"Unexpected Response: 408 (Request Timeout)\\nRaw response content:\\nb''\"}\n",
      "finished: {'start_date': '2015-03-23', 'end_date': '2015-03-29', 'collection_name': 'wsb_2015-03-23_2015-03-29', 'error': \"Unexpected Response: 408 (Request Timeout)\\nRaw response content:\\nb''\"}\n",
      "finished: {'start_date': '2015-05-18', 'end_date': '2015-05-24', 'collection_name': 'wsb_2015-05-18_2015-05-24', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-03-02', 'end_date': '2015-03-08', 'collection_name': 'wsb_2015-03-02_2015-03-08'}\n",
      "finished: {'start_date': '2015-06-15', 'end_date': '2015-06-21', 'collection_name': 'wsb_2015-06-15_2015-06-21', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-04-20', 'end_date': '2015-04-26', 'collection_name': 'wsb_2015-04-20_2015-04-26'}\n",
      "finished: {'start_date': '2015-06-08', 'end_date': '2015-06-14', 'collection_name': 'wsb_2015-06-08_2015-06-14'}\n",
      "finished: {'start_date': '2015-05-04', 'end_date': '2015-05-10', 'collection_name': 'wsb_2015-05-04_2015-05-10', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-05-11', 'end_date': '2015-05-17', 'collection_name': 'wsb_2015-05-11_2015-05-17', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-06-01', 'end_date': '2015-06-07', 'collection_name': 'wsb_2015-06-01_2015-06-07', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-05-25', 'end_date': '2015-05-31', 'collection_name': 'wsb_2015-05-25_2015-05-31', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-04-27', 'end_date': '2015-05-03', 'collection_name': 'wsb_2015-04-27_2015-05-03', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-06-29', 'end_date': '2015-07-05', 'collection_name': 'wsb_2015-06-29_2015-07-05', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-06-22', 'end_date': '2015-06-28', 'collection_name': 'wsb_2015-06-22_2015-06-28', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-07-06', 'end_date': '2015-07-12', 'collection_name': 'wsb_2015-07-06_2015-07-12', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-08-03', 'end_date': '2015-08-09', 'collection_name': 'wsb_2015-08-03_2015-08-09', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-07-27', 'end_date': '2015-08-02', 'collection_name': 'wsb_2015-07-27_2015-08-02', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-07-13', 'end_date': '2015-07-19', 'collection_name': 'wsb_2015-07-13_2015-07-19', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-07-20', 'end_date': '2015-07-26', 'collection_name': 'wsb_2015-07-20_2015-07-26', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-08-10', 'end_date': '2015-08-16', 'collection_name': 'wsb_2015-08-10_2015-08-16', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-08-17', 'end_date': '2015-08-23', 'collection_name': 'wsb_2015-08-17_2015-08-23', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-08-31', 'end_date': '2015-09-06', 'collection_name': 'wsb_2015-08-31_2015-09-06', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-08-24', 'end_date': '2015-08-30', 'collection_name': 'wsb_2015-08-24_2015-08-30', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-09-28', 'end_date': '2015-10-04', 'collection_name': 'wsb_2015-09-28_2015-10-04', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-09-07', 'end_date': '2015-09-13', 'collection_name': 'wsb_2015-09-07_2015-09-13', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-09-21', 'end_date': '2015-09-27', 'collection_name': 'wsb_2015-09-21_2015-09-27', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-09-14', 'end_date': '2015-09-20', 'collection_name': 'wsb_2015-09-14_2015-09-20', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-10-05', 'end_date': '2015-10-11', 'collection_name': 'wsb_2015-10-05_2015-10-11', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-10-12', 'end_date': '2015-10-18', 'collection_name': 'wsb_2015-10-12_2015-10-18', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-10-19', 'end_date': '2015-10-25', 'collection_name': 'wsb_2015-10-19_2015-10-25', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-10-26', 'end_date': '2015-11-01', 'collection_name': 'wsb_2015-10-26_2015-11-01', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-11-23', 'end_date': '2015-11-29', 'collection_name': 'wsb_2015-11-23_2015-11-29', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-11-16', 'end_date': '2015-11-22', 'collection_name': 'wsb_2015-11-16_2015-11-22', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-11-02', 'end_date': '2015-11-08', 'collection_name': 'wsb_2015-11-02_2015-11-08', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-11-30', 'end_date': '2015-12-06', 'collection_name': 'wsb_2015-11-30_2015-12-06', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-11-09', 'end_date': '2015-11-15', 'collection_name': 'wsb_2015-11-09_2015-11-15', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-12-28', 'end_date': '2016-01-03', 'collection_name': 'wsb_2015-12-28_2016-01-03', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-12-21', 'end_date': '2015-12-27', 'collection_name': 'wsb_2015-12-21_2015-12-27', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-12-07', 'end_date': '2015-12-13', 'collection_name': 'wsb_2015-12-07_2015-12-13', 'error': 'timed out'}\n",
      "finished: {'start_date': '2015-12-14', 'end_date': '2015-12-20', 'collection_name': 'wsb_2015-12-14_2015-12-20', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-01-04', 'end_date': '2016-01-10', 'collection_name': 'wsb_2016-01-04_2016-01-10', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-01-25', 'end_date': '2016-01-31', 'collection_name': 'wsb_2016-01-25_2016-01-31', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-02-01', 'end_date': '2016-02-07', 'collection_name': 'wsb_2016-02-01_2016-02-07', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-02-08', 'end_date': '2016-02-14', 'collection_name': 'wsb_2016-02-08_2016-02-14', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-01-11', 'end_date': '2016-01-17', 'collection_name': 'wsb_2016-01-11_2016-01-17', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-02-22', 'end_date': '2016-02-28', 'collection_name': 'wsb_2016-02-22_2016-02-28', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-01-18', 'end_date': '2016-01-24', 'collection_name': 'wsb_2016-01-18_2016-01-24', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-02-29', 'end_date': '2016-03-06', 'collection_name': 'wsb_2016-02-29_2016-03-06', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-02-15', 'end_date': '2016-02-21', 'collection_name': 'wsb_2016-02-15_2016-02-21', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-03-07', 'end_date': '2016-03-13', 'collection_name': 'wsb_2016-03-07_2016-03-13', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-03-14', 'end_date': '2016-03-20', 'collection_name': 'wsb_2016-03-14_2016-03-20', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-03-21', 'end_date': '2016-03-27', 'collection_name': 'wsb_2016-03-21_2016-03-27', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-03-28', 'end_date': '2016-04-03', 'collection_name': 'wsb_2016-03-28_2016-04-03', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-04-04', 'end_date': '2016-04-10', 'collection_name': 'wsb_2016-04-04_2016-04-10', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-04-11', 'end_date': '2016-04-17', 'collection_name': 'wsb_2016-04-11_2016-04-17', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-04-18', 'end_date': '2016-04-24', 'collection_name': 'wsb_2016-04-18_2016-04-24', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-04-25', 'end_date': '2016-05-01', 'collection_name': 'wsb_2016-04-25_2016-05-01', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-05-02', 'end_date': '2016-05-08', 'collection_name': 'wsb_2016-05-02_2016-05-08', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-05-09', 'end_date': '2016-05-15', 'collection_name': 'wsb_2016-05-09_2016-05-15', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-05-16', 'end_date': '2016-05-22', 'collection_name': 'wsb_2016-05-16_2016-05-22', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-05-23', 'end_date': '2016-05-29', 'collection_name': 'wsb_2016-05-23_2016-05-29', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-06-13', 'end_date': '2016-06-19', 'collection_name': 'wsb_2016-06-13_2016-06-19', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-06-06', 'end_date': '2016-06-12', 'collection_name': 'wsb_2016-06-06_2016-06-12', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-05-30', 'end_date': '2016-06-05', 'collection_name': 'wsb_2016-05-30_2016-06-05', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-06-27', 'end_date': '2016-07-03', 'collection_name': 'wsb_2016-06-27_2016-07-03', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-07-04', 'end_date': '2016-07-10', 'collection_name': 'wsb_2016-07-04_2016-07-10', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-06-20', 'end_date': '2016-06-26', 'collection_name': 'wsb_2016-06-20_2016-06-26', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-07-11', 'end_date': '2016-07-17', 'collection_name': 'wsb_2016-07-11_2016-07-17', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-08-08', 'end_date': '2016-08-14', 'collection_name': 'wsb_2016-08-08_2016-08-14', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-08-01', 'end_date': '2016-08-07', 'collection_name': 'wsb_2016-08-01_2016-08-07', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-07-25', 'end_date': '2016-07-31', 'collection_name': 'wsb_2016-07-25_2016-07-31', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-07-18', 'end_date': '2016-07-24', 'collection_name': 'wsb_2016-07-18_2016-07-24', 'error': 'timed out'}\n",
      "finished: {'start_date': '2016-08-15', 'end_date': '2016-08-21', 'collection_name': 'wsb_2016-08-15_2016-08-21', 'error': 'timed out'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m     futures\u001b[39m.\u001b[39mappend(future)\n\u001b[0;32m---> 38\u001b[0m \u001b[39mfor\u001b[39;00m future \u001b[39min\u001b[39;00m as_completed(futures):\n\u001b[1;32m     39\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfinished:\u001b[39m\u001b[39m\"\u001b[39m, future\u001b[39m.\u001b[39mresult() )\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:245\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m (of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m) futures unfinished\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[1;32m    243\u001b[0m                 \u001b[39mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 245\u001b[0m waiter\u001b[39m.\u001b[39;49mevent\u001b[39m.\u001b[39;49mwait(wait_timeout)\n\u001b[1;32m    247\u001b[0m \u001b[39mwith\u001b[39;00m waiter\u001b[39m.\u001b[39mlock:\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 574\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m     gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m     futures\u001b[39m.\u001b[39mappend(future)\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m future \u001b[39min\u001b[39;00m as_completed(futures):\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfinished:\u001b[39m\u001b[39m\"\u001b[39m, future\u001b[39m.\u001b[39mresult() )\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:636\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 636\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/process.py:740\u001b[0m, in \u001b[0;36mProcessPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_manager_thread_wakeup\u001b[39m.\u001b[39mwakeup()\n\u001b[1;32m    739\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_manager_thread \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m wait:\n\u001b[0;32m--> 740\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executor_manager_thread\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m    741\u001b[0m \u001b[39m# To reduce the risk of opening too many files, remove references to\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[39m# objects that use file descriptors.\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_manager_thread \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py:1053\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1053\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1055\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py:1069\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[39mif\u001b[39;00m lock \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# already determined that the C code is done\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_stopped\n\u001b[0;32m-> 1069\u001b[0m \u001b[39melif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1070\u001b[0m     lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1071\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# group rows for a week, ending sunday, this way the text will align with the MON market open\n",
    "weekly_df = wsb_df.resample(\"W-SUN\")\n",
    "MAX_WORKERS = 3\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = []\n",
    "    for _, group in weekly_df:\n",
    "        # starting timestamp of the group\n",
    "        start = group.index[0].strftime(\"%Y-%m-%d\")\n",
    "        # ending timestamp of the group\n",
    "        end = group.index[-1].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # we've completed indexing up to this date, so skip anything before this\n",
    "        # conditionally, remove this step if you want to re-index everything\n",
    "        # if start <= \"2016-09-19\":\n",
    "        #     continue\n",
    "\n",
    "        loader = DataFrameLoader(group, page_content_column=\"body\")\n",
    "        collection_name = f\"wsb_{start}_{end}\"\n",
    "\n",
    "        future = executor.submit(\n",
    "            try_index,\n",
    "            collection_name,\n",
    "            start,\n",
    "            end,\n",
    "            VectorstoreIndexCreator(\n",
    "                vectorstore_cls=Qdrant,\n",
    "                embedding=embeddings,\n",
    "                vectorstore_kwargs={\n",
    "                    \"url\": \"http://localhost:6333\",\n",
    "                    \"collection_name\": collection_name,\n",
    "                },\n",
    "            ).from_loaders,\n",
    "            [loader],\n",
    "        )\n",
    "        # print(\"submitted:\", collection_name)\n",
    "        futures.append(future)\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        print(\"finished:\", future.result() )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 1: Make queries against the collections\n",
    "\n",
    "Be sure to be running the Qdrant server in docker, and to have the indexes created at least once.\n",
    "\n",
    "Given any collections that are already in Docker, execute the queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Qdrant client and get all of the collections\n",
    "client = qdrant_client.QdrantClient(\"http://localhost:6333\")\n",
    "wsb_collections = [\n",
    "    c.name for c in client.get_collections().collections if c.name.startswith(\"wsb_\")\n",
    "]\n",
    "\n",
    "futures = []\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    for collection_name in wsb_collections:\n",
    "        # print(\"Found collection:\", collection_name)\n",
    "        # recreate the index\n",
    "        client = qdrant_client.QdrantClient(\"http://localhost:6333\")\n",
    "        vectorstore = Qdrant(\n",
    "            client, collection_name=collection_name, embeddings=embeddings\n",
    "        )\n",
    "        restored_index = VectorStoreIndexWrapper(\n",
    "            vectorstore=vectorstore,\n",
    "        )\n",
    "        future = executor.submit(\n",
    "            try_query,\n",
    "            collection_name,\n",
    "            restored_index.query,\n",
    "            [\n",
    "                \"What are the most trending tickers?\",\n",
    "                \"What are the biggest investment opportunities?\",\n",
    "            ],\n",
    "            llm=llm,\n",
    "        )\n",
    "        futures.append(future)\n",
    "        break\n",
    "    # wait for all of the futures to complete\n",
    "    for out in as_completed(futures):\n",
    "        this_result = out.result()\n",
    "        answers = this_result[\"answers\"]\n",
    "        print(this_result[\"collection_name\"])\n",
    "        for answer in answers:\n",
    "            print(\" \", answer[\"question\"])\n",
    "            print(\" \", answer[\"answer\"])\n",
    "\n",
    "# get all of the results for further processing..\n",
    "results = [f.result() for f in futures]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 2: Summary chain over wsb data\n",
    "\n",
    "See [lang chain summary docs](https://docs.langchain.com/docs/components/chains/index_related_chains) for the pros and cons on using summary chains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group rows for a week, ending sunday, this way the text will align with the MON market open\n",
    "weekly_df = wsb_df.resample(\"W-SUN\")\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=1) as executor:\n",
    "    futures = []\n",
    "    for _, group in weekly_df:\n",
    "        # starting timestamp of the group\n",
    "        start = group.index[0].strftime(\"%Y-%m-%d\")\n",
    "        # ending timestamp of the group\n",
    "        end = group.index[-1].strftime(\"%Y-%m-%d\")\n",
    "        collection_name = f\"wsb_{start}_{end}\"\n",
    "\n",
    "        loader = DataFrameLoader(group, page_content_column=\"body\")\n",
    "        docs = loader.load()\n",
    "        print(\"loaded:\", start, end, len(docs))\n",
    "\n",
    "        chain = load_summarize_chain(llm=llm, chain_type=\"stuff\", verbose=True)\n",
    "\n",
    "        future = executor.submit(chain.run, docs[:50])\n",
    "\n",
    "        # print(\"submitted:\", collection_name)\n",
    "        futures.append(future)\n",
    "        break\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        print(\"finished:\", future.result())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
